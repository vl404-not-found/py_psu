{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4i5b0ZSl7v8",
    "outputId": "157c7ace-b29d-40ee-99a5-96ff7b75e1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from nltk) (4.60.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: pymorphy2 in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (2.4.393442.3710985)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (1.20.2)\n",
      "Requirement already satisfied: sklearn in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from scikit-learn->sklearn) (1.20.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: regex in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from nltk) (4.60.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\miniconda3\\envs\\lipo\\lib\\site-packages (from nltk) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install pymorphy2\n",
    "!pip install pymorphy2-dicts\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oVvW_X5qmfgR"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VpNHG0-2mfwV"
   },
   "outputs": [],
   "source": [
    "with open('data.txt','r',errors = 'ignore') as f:\n",
    "  raw=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jzA8Z1ylnWFl"
   },
   "outputs": [],
   "source": [
    "raw = raw.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Aa2mJfLnhMC",
    "outputId": "7466d505-1458-48e5-cca0-c80cad7183d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iYuMLvt0nmOW"
   },
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw)\n",
    "word_tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjDfboiLnqpl",
    "outputId": "51b17636-1150-401c-ad34-642754c0565b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['во время моего недавнего визита в сша, я зашел в офис компании adobe в сан-франциско для того, чтобы по больше разузнать про apollo – новую платформу компании для разработки и выполнения ria (rich internet application).',\n",
       " 'я пообщался с майком чемберсом – продакт-менеджером ответственным за apollo, чтобы узнать, что же такое на самом деле apollo, и каково его будущее.',\n",
       " 'кристиан контрелл, другой менеджер в команде apollo, присоединился к нам в середине разговора, чтобы показать мне некоторые новые приложения сделанные с помощью apollo.',\n",
       " 'в этом тексте я суммирую все то, что узнал об apollo, а так же добавлю краткое описание «для чайников» (потому что до этой встречи я был одним из этих «чайников»).',\n",
       " 'почти все из того, что писалось уже об apollo в блогах и сми отражало преимущества apollo для разработчиков, я же хочу так же представить удобства apollo для конечного пользователя, так что этот текст являет собой некую попытку это сделать.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yahyv942n9Xa",
    "outputId": "f66992e6-a8a4-4676-d582-d2e0c2fc1a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['во', 'время', 'моего', 'недавнего', 'визита']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7BceOVEXoH7B"
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "lemmer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U2sfjMPOI1NQ"
   },
   "outputs": [],
   "source": [
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# eng_lemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "67kTveWyJPJK",
    "outputId": "bfb662bf-a45e-4398-f948-7c071074094a"
   },
   "outputs": [],
   "source": [
    "# eng_lemmer.lemmatize('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TPNXz4Kfn_3n"
   },
   "outputs": [],
   "source": [
    "def LemTokens(tokens):\n",
    "    return [lemmer.parse(token)[0].normal_form for token in tokens]\n",
    "    # return [eng_lemmer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vLiNxI4-oyGo"
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from IPython.display import HTML\n",
    "\n",
    "# Тут нужно менять!\n",
    "GREETING_INPUTS = (\"привет\", \"здравствуйте\", \"здорово\", \"чо каво\", \"хай\", \"салют\", \"хаюшки\")\n",
    "GREETING_RESPONSES = [\"привет\", \"хай\", \"*подмигнул*\", \"здарова\", \"здравствуй\", \"рад общению с тобой\"]\n",
    "STRANGE_ITEM = (\"абоба\")\n",
    "\n",
    "called=False\n",
    "\n",
    "def greeting(sentence):\n",
    "    global called\n",
    "    if len(sentence.split()) > 0:\n",
    "        sentence = re.sub('[^А-Яа-яё ]', '', sentence)\n",
    "#         sentence = re.sub('[^A-Za-z ]', '', sentence)\n",
    "    if sentence in STRANGE_ITEM and not called:\n",
    "        display(HTML('<iframe allow=\"autoplay\" width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3HrSVXP99kQ?autoplay=1\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'))\n",
    "        called = True\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JcCVEtzopZS0"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9Kf3-Rx5peRP"
   },
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopwords.words(\"russian\"))\n",
    "    # TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"Извини, но я не понимаю тебя!\" # ТУТ можно менять :) \n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU2whSa7prjz",
    "outputId": "28c4f2b4-fa4e-4204-94d2-0ab2036dfe50",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Робот: Да Да. \n",
      "Мне лень писать сввоё имя, но если ты спросишь... \n",
      "Хочешь мем введи абоба\n",
      "абоба\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe allow=\"autoplay\" width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3HrSVXP99kQ?autoplay=1\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Робот: абоба\n",
      "привет\n",
      "Робот: здравствуй\n",
      "кто ты \n",
      "Робот: Извини, но я не понимаю тебя!\n",
      "apollo\n",
      "Робот: apollo\n",
      "\n",
      "второй наш кандидат – это apollo.\n",
      "о чём речь\n",
      "Робот: речь идёт о хуках usequery, usemutation и usesubscription.\n",
      "библиотека\n",
      "Робот: таким образом, мы выбрали библиотеку и пошли работать.\n",
      "GraphQl\n",
      "Робот: что такое graphql?\n",
      "как тебя зовут\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe allow=\"autoplay\" width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/W85F-UmnbF4?start=39&autoplay=1\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Робот: меня зовут oveveveevuev eyentanebwueve ugmbagbem osas!\n",
      "пока\n",
      "Робот: Пока-пока! *машет-ручкой*\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "flag=True\n",
    "\n",
    "# Тут тоже нужно менять!\n",
    "print(\"Робот: Да Да. \\nМне лень писать сввоё имя, но если ты спросишь... \\nХочешь мем введи абоба\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='пока'):\n",
    "        if(user_response in ['благодарю', 'спс']): # И тут меняйте :)\n",
    "            flag=False\n",
    "            print(\"Робот: Иче??? ;)\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"Робот: \"+greeting(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words=list(set(word_tokens))\n",
    "                if user_response == \"как тебя зовут\":\n",
    "                    display(HTML('<iframe allow=\"autoplay\" width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/W85F-UmnbF4?start=39&autoplay=1\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'))\n",
    "                print(\"Робот: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Робот: Пока-пока! *машет-ручкой*\") # Тут тоже нужно импровизировать"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
